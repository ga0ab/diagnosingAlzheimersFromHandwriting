{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0ed83e-b812-40d4-bb05-0f288ae4374d",
   "metadata": {},
   "source": [
    "## Our initial analysis focused on evaluating the performance of the four selected classifiers using the complete DARWIN data set with all 450 features.\n",
    "\n",
    "This approach served as our baseline, providing a fundamental understanding of each classifier's capability to differentiate between Alzheimer's patients and healthy controls.\n",
    "\n",
    "### **This notebook contains the baseline for the Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab733ee-55ed-449e-882e-7b42b680e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Aggregated Performance Metrics with 5-Fold Cross-Validation (Decision Tree):\n",
      "Mean Accuracy: 0.8390 ± 0.0391\n",
      "Mean Precision: 0.8147 ± 0.0824\n",
      "Mean Recall: 0.9031 ± 0.0891\n",
      "Mean F1 Score: 0.8497 ± 0.0404\n",
      "Mean Sensitivity: 0.9031 ± 0.0891\n",
      "Mean Specificity: 0.7839 ± 0.1020\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Fetch dataset \n",
    "darwin = fetch_ucirepo(id=732)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = darwin.data.features\n",
    "y = darwin.data.targets\n",
    "\n",
    "X = X.drop(columns=['ID'])  # Remove ID column as it's not needed\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "params = {\n",
    "    'criterion': 'gini', \n",
    "    'max_depth': 2, \n",
    "    'max_leaf_nodes': 2, \n",
    "    'min_samples_leaf': 2, \n",
    "    'min_samples_split': 2\n",
    "}\n",
    "\n",
    "# Lists to store performance metrics\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_f1_scores = []\n",
    "all_sensitivities = []\n",
    "all_specificities = []\n",
    "\n",
    "# Set up 10-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Ensure y_train and y_test are 1D\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Create Decision Tree classifier with the specified parameters\n",
    "    clf_dt = DecisionTreeClassifier(**params, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = clf_dt.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary', pos_label='P')\n",
    "    recall = recall_score(y_test, y_pred, average='binary', pos_label='P')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary', pos_label='P')\n",
    "\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1_scores.append(f1)\n",
    "\n",
    "    # Calculate confusion matrix components\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=['H', 'P'])\n",
    "    if cm.shape == (2, 2):  # Ensure it's a 2x2 matrix for binary classification\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else:\n",
    "        print(f\"Unexpected confusion matrix shape: {cm.shape}\")\n",
    "        sensitivity = specificity = 0\n",
    "\n",
    "    all_sensitivities.append(sensitivity)\n",
    "    all_specificities.append(specificity)\n",
    "\n",
    "# Calculate overall mean and standard deviation for metrics\n",
    "final_metrics = {\n",
    "    'mean_accuracy': np.mean(all_accuracies),\n",
    "    'std_accuracy': np.std(all_accuracies),\n",
    "    'mean_precision': np.mean(all_precisions),\n",
    "    'std_precision': np.std(all_precisions),\n",
    "    'mean_recall': np.mean(all_recalls),\n",
    "    'std_recall': np.std(all_recalls),\n",
    "    'mean_f1_score': np.mean(all_f1_scores),\n",
    "    'std_f1_score': np.std(all_f1_scores),\n",
    "    'mean_sensitivity': np.mean(all_sensitivities),\n",
    "    'std_sensitivity': np.std(all_sensitivities),\n",
    "    'mean_specificity': np.mean(all_specificities),\n",
    "    'std_specificity': np.std(all_specificities),\n",
    "}\n",
    "\n",
    "# Print the final aggregated metrics\n",
    "print(\"Final Aggregated Performance Metrics with 5-Fold Cross-Validation (Decision Tree):\")\n",
    "print(f\"Mean Accuracy: {final_metrics['mean_accuracy']:.4f} ± {final_metrics['std_accuracy']:.4f}\")\n",
    "print(f\"Mean Precision: {final_metrics['mean_precision']:.4f} ± {final_metrics['std_precision']:.4f}\")\n",
    "print(f\"Mean Recall: {final_metrics['mean_recall']:.4f} ± {final_metrics['std_recall']:.4f}\")\n",
    "print(f\"Mean F1 Score: {final_metrics['mean_f1_score']:.4f} ± {final_metrics['std_f1_score']:.4f}\")\n",
    "print(f\"Mean Sensitivity: {final_metrics['mean_sensitivity']:.4f} ± {final_metrics['std_sensitivity']:.4f}\")\n",
    "print(f\"Mean Specificity: {final_metrics['mean_specificity']:.4f} ± {final_metrics['std_specificity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4a70eb-5918-4b54-b417-1f7794365986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9142857142857143,\n",
       " 0.8285714285714286,\n",
       " 0.8285714285714286,\n",
       " 0.8,\n",
       " 0.8235294117647058]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbe7570-8e91-4be8-b8e2-77aefabfd049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9473684210526315),\n",
       " np.float64(0.7619047619047619),\n",
       " np.float64(0.7391304347826086),\n",
       " np.float64(0.875),\n",
       " np.float64(0.75)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adc5789-90ca-4a5e-91fb-e15d419635f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9),\n",
       " np.float64(0.9411764705882353),\n",
       " np.float64(1.0),\n",
       " np.float64(0.7368421052631579),\n",
       " np.float64(0.9375)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df515a7-4944-4ec9-a252-69626bb59cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9230769230769231),\n",
       " np.float64(0.8421052631578947),\n",
       " np.float64(0.85),\n",
       " np.float64(0.8),\n",
       " np.float64(0.8333333333333334)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156b4ed4-40f6-4f02-8a68-d74fae430e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9),\n",
       " np.float64(0.9411764705882353),\n",
       " np.float64(1.0),\n",
       " np.float64(0.7368421052631579),\n",
       " np.float64(0.9375)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed483b31-7e6d-4281-94b4-773f497b3349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9333333333333333),\n",
       " np.float64(0.7222222222222222),\n",
       " np.float64(0.6666666666666666),\n",
       " np.float64(0.875),\n",
       " np.float64(0.7222222222222222)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_specificities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d440cbb-2904-42ac-864f-435ebcd52d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
