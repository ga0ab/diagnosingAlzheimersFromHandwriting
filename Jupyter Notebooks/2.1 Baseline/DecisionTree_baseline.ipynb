{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830fbb27-f922-4db1-9607-5d34654f41d8",
   "metadata": {},
   "source": [
    "## As an alternative to k-fold cross-validation, we also performed something which was suggested in the reference paper: \n",
    "\n",
    "\"To reduce as much as possible the bias introduced by the randomness in selecting the samples of the training and test set, we performed twenty runs. In each run, the dataset was randomly shuffled and split into a training and a test set.\"\n",
    "\n",
    "### Cf. Section 2.1 of our report (we proved there is no significant statistical difference between the results we get with this methodology and k-fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dc313-0118-42f7-be01-03f62ee01e1d",
   "metadata": {},
   "source": [
    "## Decision Tree (20 itearations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebaae9a-476c-4486-99ca-36cdc25d6f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Aggregated Performance Metrics:\n",
      "Mean Accuracy: 0.8386 ± 0.0690\n",
      "Mean Precision: 0.8052 ± 0.0757\n",
      "Mean Recall: 0.9139 ± 0.0621\n",
      "Mean F1 Score: 0.8545 ± 0.0599\n",
      "Mean Sensitivity: 0.9139 ± 0.0621\n",
      "Mean Specificity: 0.7588 ± 0.1067\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch dataset \n",
    "darwin = fetch_ucirepo(id=732)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = darwin.data.features\n",
    "y = darwin.data.targets\n",
    "\n",
    "X = X.drop(columns=['ID'])  # Remove ID column as it's not needed\n",
    "\n",
    "# Number of runs\n",
    "n_runs = 20\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "params = {\n",
    "    'criterion': 'gini', \n",
    "    'max_depth': 2, \n",
    "    'max_leaf_nodes': 2, \n",
    "    'min_samples_leaf': 2, \n",
    "    'min_samples_split': 2\n",
    "}\n",
    "\n",
    "# Lists to store performance metrics\n",
    "all_accuracies = []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_f1_scores = []\n",
    "all_sensitivities = []\n",
    "all_specificities = []\n",
    "\n",
    "# Run the model multiple times for robustness\n",
    "for run in range(n_runs):\n",
    "    # Shuffle and split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=None, stratify=y\n",
    "    )\n",
    "\n",
    "    # Ensure y_train and y_test are 1D\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Create Decision Tree classifier with the specified parameters\n",
    "    clf_dt = DecisionTreeClassifier(**params, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = clf_dt.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary', pos_label='P')  # Explicitly define pos_label\n",
    "    recall = recall_score(y_test, y_pred, average='binary', pos_label='P')        # Explicitly define pos_label\n",
    "    f1 = f1_score(y_test, y_pred, average='binary', pos_label='P')                # Explicitly define pos_label\n",
    "\n",
    "    all_accuracies.append(accuracy)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1_scores.append(f1)\n",
    "\n",
    "    # Calculate confusion matrix components\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=['H', 'P'])\n",
    "    # Correctly identify the elements of the confusion matrix\n",
    "    if cm.shape == (2, 2):  # Ensure it's a 2x2 matrix for binary classification\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    else:\n",
    "        # If it's not a 2x2 matrix, something went wrong\n",
    "        print(f\"Unexpected confusion matrix shape: {cm.shape}\")\n",
    "        sensitivity = specificity = 0\n",
    "\n",
    "    all_sensitivities.append(sensitivity)\n",
    "    all_specificities.append(specificity)\n",
    "\n",
    "# Calculate overall mean and standard deviation for metrics\n",
    "final_metrics = {\n",
    "    'mean_accuracy': np.mean(all_accuracies),\n",
    "    'std_accuracy': np.std(all_accuracies),\n",
    "    'mean_precision': np.mean(all_precisions),\n",
    "    'std_precision': np.std(all_precisions),\n",
    "    'mean_recall': np.mean(all_recalls),\n",
    "    'std_recall': np.std(all_recalls),\n",
    "    'mean_f1_score': np.mean(all_f1_scores),\n",
    "    'std_f1_score': np.std(all_f1_scores),\n",
    "    'mean_sensitivity': np.mean(all_sensitivities),\n",
    "    'std_sensitivity': np.std(all_sensitivities),\n",
    "    'mean_specificity': np.mean(all_specificities),\n",
    "    'std_specificity': np.std(all_specificities),\n",
    "}\n",
    "\n",
    "# Print the final aggregated metrics\n",
    "print(\"Final Aggregated Performance Metrics:\")\n",
    "print(f\"Mean Accuracy: {final_metrics['mean_accuracy']:.4f} ± {final_metrics['std_accuracy']:.4f}\")\n",
    "print(f\"Mean Precision: {final_metrics['mean_precision']:.4f} ± {final_metrics['std_precision']:.4f}\")\n",
    "print(f\"Mean Recall: {final_metrics['mean_recall']:.4f} ± {final_metrics['std_recall']:.4f}\")\n",
    "print(f\"Mean F1 Score: {final_metrics['mean_f1_score']:.4f} ± {final_metrics['std_f1_score']:.4f}\")\n",
    "print(f\"Mean Sensitivity: {final_metrics['mean_sensitivity']:.4f} ± {final_metrics['std_sensitivity']:.4f}\")\n",
    "print(f\"Mean Specificity: {final_metrics['mean_specificity']:.4f} ± {final_metrics['std_specificity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131f868d-b7ef-496b-821e-52c6f0484ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8285714285714286,\n",
       " 0.8571428571428571,\n",
       " 0.8285714285714286,\n",
       " 0.8285714285714286,\n",
       " 0.7142857142857143,\n",
       " 0.7428571428571429,\n",
       " 0.8857142857142857,\n",
       " 0.6571428571428571,\n",
       " 0.9428571428571428,\n",
       " 0.8285714285714286,\n",
       " 0.8571428571428571,\n",
       " 0.8857142857142857,\n",
       " 0.9428571428571428,\n",
       " 0.9142857142857143,\n",
       " 0.8857142857142857,\n",
       " 0.8571428571428571,\n",
       " 0.8285714285714286,\n",
       " 0.8285714285714286,\n",
       " 0.8571428571428571,\n",
       " 0.8]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2474357-c1c4-4623-98b9-9091f4379622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8333333333333334),\n",
       " np.float64(0.8095238095238095),\n",
       " np.float64(0.8),\n",
       " np.float64(0.8),\n",
       " np.float64(0.6666666666666666),\n",
       " np.float64(0.6956521739130435),\n",
       " np.float64(0.85),\n",
       " np.float64(0.65),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.75),\n",
       " np.float64(0.8095238095238095),\n",
       " np.float64(0.85),\n",
       " np.float64(0.9),\n",
       " np.float64(0.9411764705882353),\n",
       " np.float64(0.85),\n",
       " np.float64(0.782608695652174),\n",
       " np.float64(0.8),\n",
       " np.float64(0.8),\n",
       " np.float64(0.8095238095238095),\n",
       " np.float64(0.7619047619047619)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3abbb19-da92-4ace-a176-717d07f71108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8333333333333334),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.7222222222222222),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.8888888888888888)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3577b295-1a2a-48f9-b222-a58b99678781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8333333333333334),\n",
       " np.float64(0.8717948717948718),\n",
       " np.float64(0.8421052631578947),\n",
       " np.float64(0.8421052631578947),\n",
       " np.float64(0.7619047619047619),\n",
       " np.float64(0.7804878048780488),\n",
       " np.float64(0.8947368421052632),\n",
       " np.float64(0.6842105263157895),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.8571428571428571),\n",
       " np.float64(0.8717948717948718),\n",
       " np.float64(0.8947368421052632),\n",
       " np.float64(0.9473684210526315),\n",
       " np.float64(0.9142857142857143),\n",
       " np.float64(0.8947368421052632),\n",
       " np.float64(0.8780487804878049),\n",
       " np.float64(0.8421052631578947),\n",
       " np.float64(0.8421052631578947),\n",
       " np.float64(0.8717948717948718),\n",
       " np.float64(0.8205128205128205)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486b4c3a-b651-4053-8c25-aabdcbd7f41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8333333333333334),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.7222222222222222),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(1.0),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.8888888888888888),\n",
       " np.float64(0.9444444444444444),\n",
       " np.float64(0.8888888888888888)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68724906-db3b-478b-8dad-c6d68741e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_specificities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
